{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝의 지도학습(변수, 정답)의 한 알고리즘 사용\n",
    "- 나이브 베이즈 분류(Naive Bayes Classifier)\n",
    "- 두 사건을 서로 독립적이라고 가정, 각각의 조건부 확률을 계산\n",
    "- 방식\n",
    " > 샘플 문장 제시 -> 긍정/부정인지 답안 제시  \n",
    " > 학습(문장을 형태소로 분해해서 학습용 데이터로 구성)  \n",
    " > 학습 후 모델이 생성되면, 한번도 접하지 않은 문장으로 예측 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 : pos / 부정 : neg\n",
    "# 데이터 구성 -> 학습용 : 테스트용 = 75 : 25\n",
    "train = [ ('i like you', 'pos'), \n",
    "         ('i hate you', 'neg'), \n",
    "         ('you like me', 'neg'), \n",
    "         ('i like her', 'pos') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### word_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like you\n",
      "['i', 'like', 'you']\n",
      "i\n",
      "like\n",
      "you\n",
      "i hate you\n",
      "['i', 'hate', 'you']\n",
      "i\n",
      "hate\n",
      "you\n",
      "you like me\n",
      "['you', 'like', 'me']\n",
      "you\n",
      "like\n",
      "me\n",
      "i like her\n",
      "['i', 'like', 'her']\n",
      "i\n",
      "like\n",
      "her\n"
     ]
    }
   ],
   "source": [
    "for sentence in train :\n",
    "    print(sentence[0])\n",
    "    # word_tokenize : 한글의 형태소로 분해하는 과정과 유사\n",
    "    print(word_tokenize(sentence[0]))    # 공백 단위로 문장을 쪼갠다\n",
    "    for word in word_tokenize(sentence[0]) :\n",
    "        # 알파벳은 대문자 혹은 소문자로 일치시킨다\n",
    "        print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'me', 'her', 'like', 'i', 'hate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문장에서 형태소로 분해하여 중복을 제거하고 리스트로 담아라\n",
    "# for sentence in train :\n",
    "#    for word in word_tokenize(sentence[0]) :\n",
    "#        print(word.lower())\n",
    "all_words = list(set([word.lower() \n",
    "                      for sentence in train \n",
    "                      for word in word_tokenize(sentence[0])]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos {'you': True}\n",
      "pos {'me': False}\n",
      "pos {'her': False}\n",
      "pos {'like': True}\n",
      "pos {'i': True}\n",
      "pos {'hate': False}\n",
      "neg {'you': True}\n",
      "neg {'me': False}\n",
      "neg {'her': False}\n",
      "neg {'like': False}\n",
      "neg {'i': True}\n",
      "neg {'hate': True}\n",
      "neg {'you': True}\n",
      "neg {'me': True}\n",
      "neg {'her': False}\n",
      "neg {'like': True}\n",
      "neg {'i': False}\n",
      "neg {'hate': False}\n",
      "pos {'you': False}\n",
      "pos {'me': False}\n",
      "pos {'her': True}\n",
      "pos {'like': True}\n",
      "pos {'i': True}\n",
      "pos {'hate': False}\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 텍스트 문장에 all_words의 내용을 대비하여 해당 말뭉치가 있는지 없는지 체크\n",
    "for x in train :\n",
    "    for word in all_words :\n",
    "        # print(word)\n",
    "        print(x[1], { word : word in word_tokenize(x[0]) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos {'you': True, 'me': False, 'her': False, 'like': True, 'i': True, 'hate': False}\n",
      "neg {'you': True, 'me': False, 'her': False, 'like': False, 'i': True, 'hate': True}\n",
      "neg {'you': True, 'me': True, 'her': False, 'like': True, 'i': False, 'hate': False}\n",
      "pos {'you': False, 'me': False, 'her': True, 'like': True, 'i': True, 'hate': False}\n"
     ]
    }
   ],
   "source": [
    "for x in train :\n",
    "    print(x[1], { word : word in word_tokenize(x[0]) for word in all_words })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'you': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'like': True,\n",
       "   'i': True,\n",
       "   'hate': False},\n",
       "  'pos'),\n",
       " ({'you': True,\n",
       "   'me': False,\n",
       "   'her': False,\n",
       "   'like': False,\n",
       "   'i': True,\n",
       "   'hate': True},\n",
       "  'neg'),\n",
       " ({'you': True,\n",
       "   'me': True,\n",
       "   'her': False,\n",
       "   'like': True,\n",
       "   'i': False,\n",
       "   'hate': False},\n",
       "  'neg'),\n",
       " ({'you': False,\n",
       "   'me': False,\n",
       "   'her': True,\n",
       "   'like': True,\n",
       "   'i': True,\n",
       "   'hate': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ ({ word : word in word_tokenize(x[0]) for word in all_words }, x[1])\n",
    "     for x in train ]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "# 알고리즘 생성 및 학습을 한 번에 진행\n",
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과, 분류의 결과치\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_sentence = 'i like MeRui'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': False,\n",
       " 'me': False,\n",
       " 'her': False,\n",
       " 'like': True,\n",
       " 'i': True,\n",
       " 'hate': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_sentence를 위처럼 딕셔너리 형태로 구성\n",
    "test_sentence_feature = { word.lower() : (word in word_tokenize(test_sentence)) for word in all_words }\n",
    "test_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "classifier.classify( test_sentence_feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한글 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "train = [ ('아웃백이 좋아', 'pos'), \n",
    "         ('애슐리도 좋아', 'pos'), \n",
    "         ('난 자연당이 싫어', 'neg'), \n",
    "         ('아웃백은 아주 좋은 식당이야', 'pos'), \n",
    "         ('난 수업 마치고 아웃백에 갈 거야', 'pos') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'갈',\n",
       " '거야',\n",
       " '난',\n",
       " '마치고',\n",
       " '수업',\n",
       " '식당이야',\n",
       " '싫어',\n",
       " '아웃백에',\n",
       " '아웃백은',\n",
       " '아웃백이',\n",
       " '아주',\n",
       " '애슐리도',\n",
       " '자연당이',\n",
       " '좋아',\n",
       " '좋은'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 준비\n",
    "# 중복 제거\n",
    "# nltk의 tokenizer는 공백 기준으로 명사품사 등을 쪼개지 않고 그대로 워드화\n",
    "\n",
    "# for sentence in train :\n",
    "#     for word in word_tokenize(sentence[0]) :\n",
    "#         print(word)\n",
    "all_words = set([word \n",
    "                 for sentence in train \n",
    "                 for word in word_tokenize(sentence[0])])\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'거야': False,\n",
       "   '식당이야': False,\n",
       "   '좋아': True,\n",
       "   '수업': False,\n",
       "   '갈': False,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '싫어': False,\n",
       "   '애슐리도': False,\n",
       "   '난': False,\n",
       "   '아웃백은': False,\n",
       "   '마치고': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백이': True,\n",
       "   '좋은': False},\n",
       "  'pos'),\n",
       " ({'거야': False,\n",
       "   '식당이야': False,\n",
       "   '좋아': True,\n",
       "   '수업': False,\n",
       "   '갈': False,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '싫어': False,\n",
       "   '애슐리도': True,\n",
       "   '난': False,\n",
       "   '아웃백은': False,\n",
       "   '마치고': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백이': False,\n",
       "   '좋은': False},\n",
       "  'pos'),\n",
       " ({'거야': False,\n",
       "   '식당이야': False,\n",
       "   '좋아': False,\n",
       "   '수업': False,\n",
       "   '갈': False,\n",
       "   '자연당이': True,\n",
       "   '아주': False,\n",
       "   '싫어': True,\n",
       "   '애슐리도': False,\n",
       "   '난': True,\n",
       "   '아웃백은': False,\n",
       "   '마치고': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백이': False,\n",
       "   '좋은': False},\n",
       "  'neg'),\n",
       " ({'거야': False,\n",
       "   '식당이야': True,\n",
       "   '좋아': False,\n",
       "   '수업': False,\n",
       "   '갈': False,\n",
       "   '자연당이': False,\n",
       "   '아주': True,\n",
       "   '싫어': False,\n",
       "   '애슐리도': False,\n",
       "   '난': False,\n",
       "   '아웃백은': True,\n",
       "   '마치고': False,\n",
       "   '아웃백에': False,\n",
       "   '아웃백이': False,\n",
       "   '좋은': True},\n",
       "  'pos'),\n",
       " ({'거야': True,\n",
       "   '식당이야': False,\n",
       "   '좋아': False,\n",
       "   '수업': True,\n",
       "   '갈': True,\n",
       "   '자연당이': False,\n",
       "   '아주': False,\n",
       "   '싫어': False,\n",
       "   '애슐리도': False,\n",
       "   '난': True,\n",
       "   '아웃백은': False,\n",
       "   '마치고': True,\n",
       "   '아웃백에': True,\n",
       "   '아웃백이': False,\n",
       "   '좋은': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ ({ word : (word in word_tokenize(x[0])) for word in all_words }, x[1]) \n",
    "        for x in train ]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                      좋은 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백이 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                       갈 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백에 = False             neg : pos    =      1.1 : 1.0\n",
      "                      아주 = False             neg : pos    =      1.1 : 1.0\n",
      "                    애슐리도 = False             neg : pos    =      1.1 : 1.0\n",
      "                    식당이야 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 문장\n",
    "test_sentence = '난 수업 마치고 아웃백에 갈 거야'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'거야': True,\n",
       " '식당이야': False,\n",
       " '좋아': False,\n",
       " '수업': True,\n",
       " '갈': True,\n",
       " '자연당이': False,\n",
       " '아주': False,\n",
       " '싫어': False,\n",
       " '애슐리도': False,\n",
       " '난': True,\n",
       " '아웃백은': False,\n",
       " '마치고': True,\n",
       " '아웃백에': True,\n",
       " '아웃백이': False,\n",
       " '좋은': False}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence_feature = { word : (word in word_tokenize(test_sentence)) for word in all_words }\n",
    "test_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sentence_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 방식을 진행을 하려면 훈련에 필요한 다량의 데이터(문장, 상황)이 필요하다\n",
    "# 훈련량이 적거나, 데이터가 적으면 부정확하다(정확도가 떨어진다)\n",
    "# 절차적인 것만 체크, 한계적인 상황을 고려\n",
    "# 지도학습은 정답을 알고 있어야 한다.\n",
    "# 다양하게 구성할 수 있는 문장에 대한 판단이 쉽지 않다\n",
    "# => 많은 문장과 문서 중에서 유사한 문장을 찾아내고\n",
    "# => 문장을 벡터로 표현하여, 벡터 간의 거리를 구하여 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 1) # 1은 임시값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 많은 문장을 훈련시커야 한다\n",
    "# 여기서는 몇 가지 샘플로 진행(절차에 집중)\n",
    "contents = [\n",
    "    '길동이랑 술마시고 싶지만 바쁜데 어떡하죠?', \n",
    "    '길동이는 공원에서 산책하고 노는 것을 싫어해요', \n",
    "    '길동이는 공원에서 노는 것도 싫어해요. 이상해요.', \n",
    "    '먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못 하고 있어요.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['것도',\n",
       " '것을',\n",
       " '곳으로',\n",
       " '공원에서',\n",
       " '그러질',\n",
       " '길동이는',\n",
       " '길동이랑',\n",
       " '너무',\n",
       " '노는',\n",
       " '떠나고',\n",
       " '바빠서',\n",
       " '바쁜데',\n",
       " '산책하고',\n",
       " '술마시고',\n",
       " '싫어해요',\n",
       " '싶은데',\n",
       " '싶지만',\n",
       " '어떡하죠',\n",
       " '여행을',\n",
       " '이상해요',\n",
       " '있어요',\n",
       " '하고']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 4), array([[0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1]], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 feature에 대한 벡터값\n",
    "trans = X.toarray().transpose()\n",
    "trans.shape, trans\n",
    "# 해석\n",
    "# '것도'라는 feature는\n",
    "# 훈련용 전체 문장 4개 중 3번째에 등장한다\n",
    "# -> [0, 0, 1, 0]이라는 벡터값을 가지게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 22)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장이 4개\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 4개에서 추출한 말뭉치 22개\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 문장\n",
    "new_post = ['길동이랑 공원에서 산책하고 놀고 싶어요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post_vec = vectorizer.transform(new_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장의 벡터화\n",
    "new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 판단을 하기 위해서 거리 계산\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 계산\n",
    "def dis_raw(v1, v2) :\n",
    "    delta = v1-v2\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.449490\n",
      "1 2.236068\n",
      "2 2.645751\n",
      "3 3.464102\n"
     ]
    }
   ],
   "source": [
    "# 샘플 문장을 반복하면서 이 문장과 일일이 비교\n",
    "# -> 그 중에서 거리가 가장 짧은 문장 선택\n",
    "# 그 문장이 가장 유사한 문장이다\n",
    "best_distance = 1000 # 임의값\n",
    "best_index = None\n",
    "for i in range(num_samples) :\n",
    "    # 각 문장의 벡터 정보를 return\n",
    "    post_vec = X.getrow(i)\n",
    "    # 비교 문장 : new_post_vec\n",
    "    d = dis_raw(post_vec, new_post_vec)\n",
    "    print(\"%d %f\" % (i, d))\n",
    "    if d < best_distance :\n",
    "        best_distance = d\n",
    "        best_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.23606797749979, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소 거리와 그 때의 인덱스\n",
    "best_distance, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'길동이는 공원에서 산책하고 노는 것을 싫어해요'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그 때 문장은\n",
    "contents[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_post = ['길동이랑 공원에서 산책하고 놀고 싶어요']와\n",
    "# 가장 유사도를 가진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> nltk의 말뭉치는 한글과 딱히 맞지 않다\n",
    "# 한글 전용 형태소 분석기를 활용하여 보다 정확하고 의미있게 작업을 진행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
