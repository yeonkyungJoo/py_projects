{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. term frequency(tf)\n",
    "    - 어떤 단어가 문서 내에서 자주 등장할수록, 중요도가 높아진다\n",
    "2. inverse document frequency(idf)\n",
    "    - 비교하는 모든 문서 내에서 만약에 같은 단어가 존재한다면, 핵심 어휘일 수도 있다 \n",
    "    - 그러나, 문서 간의 비교에서는 중요한 단어가 아닐 수 있다  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텍스트 마이닝에서 사용하는 기법\n",
    "- 단어별로 가중치를 부과하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for w in set(['a', 'b', 'b']) :  # {a, b}\n",
    "    print(['a', 'b', 'b'].count(w))   # a는 1개, b는 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 2]\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# d.count(w) for w in set(d)\n",
    "# 문장 안의 단어별 빈도수\n",
    "print([['a'].count(w) for w in set(['a'])])\n",
    "print([['a', 'b', 'b'].count(w) for w in set(['a', 'b', 'b'])])\n",
    "print([['a', 'b', 'c'].count(w) for w in set(['a', 'b', 'c'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, abb, abc = ['a'], ['a', 'b', 'b'], ['a', 'b', 'c']\n",
    "# 여러 문장을 모아 둔 리스트\n",
    "D = [a, abb, abc]\n",
    "len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'b']\n",
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "for doc in D :\n",
    "    if 'b' in doc :\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 리스트 내에서 해당 단어가 포함된 문장의 개수\n",
    "len([ doc for doc in D if 'b' in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 구성\n",
    "'''\n",
    "t : 단어, 'a' or 'b' or 'c'\n",
    "d : 문장을 가진 한 세트, ['a', 'b', 'b']\n",
    "D : 문장 리스트를 멤버로 가진 리스트(비교할 문장 덩어리), \n",
    "    [['a'], ['a', 'b', 'b'], ['a', 'b', 'c']]\n",
    "'''\n",
    "def tfidf(t, d, D) :\n",
    "    # tf : 문장 전체의 단어 빈도수 대비 해당 단어의 빈도수 비율\n",
    "    tf = float(d.count(t)) / sum(d.count(w) for w in set(d))\n",
    "    \n",
    "    idf = sp.log(float(len(D)) / len([ doc for doc in D if 'b' in doc]))\n",
    "    return tf, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.4054651081081644)\n",
      "(0.6666666666666666, 0.4054651081081644)\n",
      "(0.3333333333333333, 0.4054651081081644)\n",
      "(0.3333333333333333, 0.4054651081081644)\n",
      "(0.3333333333333333, 0.4054651081081644)\n"
     ]
    }
   ],
   "source": [
    "# 단어 빈도수가 1인데 'a'도 1번 등장했으므로 tf = 1\n",
    "print(tfidf('a', a, D))\n",
    "# 단어 빈도수가 3인데 'b'는 2번 등장했으므로 tf = 0.67\n",
    "print(tfidf('b', abb, D))\n",
    "print(tfidf('a', abc, D))\n",
    "print(tfidf('b', abc, D))\n",
    "print(tfidf('c', abc, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### vectorizer = TfidfVectorizer(min_df = 1, decode_error = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리로 처리\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 1, decode_error = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기\n",
    "from konlpy.tag import Okt\n",
    "t = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [\n",
    "    '길동이랑 술마시고 싶지만 바쁜데 어떡하죠?', \n",
    "    '길동이는 공원에서 산책하고 노는 것을 싫어해요', \n",
    "    '길동이는 공원에서 노는 것도 싫어해요. 이상해요.', \n",
    "    '먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못 하고 있어요.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['길동', '이랑', '술', '마시고', '싶지만', '바쁜데', '어떡하죠', '?']\n",
      "['길동', '이', '는', '공원', '에서', '산책', '하고', '노', '는', '것', '을', '싫어해요']\n",
      "['길동', '이', '는', '공원', '에서', '노', '는', '것', '도', '싫어해요', '.', '이상해요', '.']\n",
      "['먼', '곳', '으로', '여행', '을', '떠나고', '싶은데', '너무', '바빠서', '그러질', '못', '하고', '있어요', '.']\n"
     ]
    }
   ],
   "source": [
    "for doc in contents :\n",
    "    # print(doc)\n",
    "    print(t.morphs(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['길동', '이랑', '술', '마시고', '싶지만', '바쁜데', '어떡하죠', '?'],\n",
       " ['길동', '이', '는', '공원', '에서', '산책', '하고', '노', '는', '것', '을', '싫어해요'],\n",
       " ['길동', '이', '는', '공원', '에서', '노', '는', '것', '도', '싫어해요', '.', '이상해요', '.'],\n",
       " ['먼',\n",
       "  '곳',\n",
       "  '으로',\n",
       "  '여행',\n",
       "  '을',\n",
       "  '떠나고',\n",
       "  '싶은데',\n",
       "  '너무',\n",
       "  '바빠서',\n",
       "  '그러질',\n",
       "  '못',\n",
       "  '하고',\n",
       "  '있어요',\n",
       "  '.']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_tokens = [ t.morphs(doc) for doc in contents ]\n",
    "contents_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents_tokens), len(contents_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['길동', '이랑', '술', '마시고', '싶지만', '바쁜데', '어떡하죠', '?']\n",
      "['길동', '이', '는', '공원', '에서', '산책', '하고', '노', '는', '것', '을', '싫어해요']\n",
      "['길동', '이', '는', '공원', '에서', '노', '는', '것', '도', '싫어해요', '.', '이상해요', '.']\n",
      "['먼', '곳', '으로', '여행', '을', '떠나고', '싶은데', '너무', '바빠서', '그러질', '못', '하고', '있어요', '.']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 기반으로 문장을 재구성\n",
    "# '길동', '이랑', '술', '마시고', '싶지만', '바쁜데', '어떡하죠', '?'\n",
    "# => 길동 이랑 술 마시고 싶지만 바쁜데 어떡하죠 ?\n",
    "contents_for_vectorize = []\n",
    "for content in contents_tokens :\n",
    "    print(content)\n",
    "    tmp = ''\n",
    "    for word in content :\n",
    "        tmp = tmp + ' ' + word\n",
    "    contents_for_vectorize.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 길동 이랑 술 마시고 싶지만 바쁜데 어떡하죠 ?',\n",
       " ' 길동 이 는 공원 에서 산책 하고 노 는 것 을 싫어해요',\n",
       " ' 길동 이 는 공원 에서 노 는 것 도 싫어해요 . 이상해요 .',\n",
       " ' 먼 곳 으로 여행 을 떠나고 싶은데 너무 바빠서 그러질 못 하고 있어요 .']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_for_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 방법\n",
    "contents_for_vectorize = []\n",
    "contents_for_vectorize = [' '.join(content) for content in contents_tokens ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['길동 이랑 술 마시고 싶지만 바쁜데 어떡하죠 ?',\n",
       " '길동 이 는 공원 에서 산책 하고 노 는 것 을 싫어해요',\n",
       " '길동 이 는 공원 에서 노 는 것 도 싫어해요 . 이상해요 .',\n",
       " '먼 곳 으로 여행 을 떠나고 싶은데 너무 바빠서 그러질 못 하고 있어요 .']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_for_vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 벡터화 : vectorizer.fit_transform( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터화\n",
    "X = vectorizer.fit_transform(contents_for_vectorize)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 크기를 변수로 받는다\n",
    "num_samples, num_features = X.shape\n",
    "num_samples, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['공원',\n",
       " '그러질',\n",
       " '길동',\n",
       " '너무',\n",
       " '떠나고',\n",
       " '마시고',\n",
       " '바빠서',\n",
       " '바쁜데',\n",
       " '산책',\n",
       " '싫어해요',\n",
       " '싶은데',\n",
       " '싶지만',\n",
       " '어떡하죠',\n",
       " '에서',\n",
       " '여행',\n",
       " '으로',\n",
       " '이랑',\n",
       " '이상해요',\n",
       " '있어요',\n",
       " '하고']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터의 특성화값 -> 컬럼 -> 변수, 특성\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['길동', '이랑', '공원', '에서', '산책', '하고', '놀고', '싶어요']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신규 문장 -> 벡터화\n",
    "# 1. 신문장\n",
    "new_post = ['길동이랑 공원에서 산책하고 놀고 싶어요']\n",
    "# 2. 형태소 분리\n",
    "new_post_tokens = [t.morphs(doc) for doc in new_post]\n",
    "new_post_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['길동 이랑 공원 에서 산책 하고 놀고 싶어요']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 형태소 단위로 문장 재구성\n",
    "new_post_for_vectorize = [' '.join(content) for content in new_post_tokens]\n",
    "new_post_for_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터화\n",
    "new_post_vec = vectorizer.transform(new_post_for_vectorize)\n",
    "new_post_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 적용하여 거리 계산(벡터화)\n",
    "def dist_norm(v1, v2) :\n",
    "    # 각각 벡터 문장의 정규화\n",
    "    v1_norm = v1 / sp.linalg.norm(v1.toarray())\n",
    "    v2_norm = v2 / sp.linalg.norm(v2.toarray())\n",
    "    # 두 문장의 거리(차이) 계산\n",
    "    delta = v1_norm - v2_norm\n",
    "    # 결과 리턴\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검사\n",
    "best_doc = None\n",
    "best_distance = 1000\n",
    "best_index = None\n",
    "for i in range(num_samples) : # num_samples : 데이터 수\n",
    "    # 비교 문장의 벡터값 획득\n",
    "    post_vec = X.getrow(i)\n",
    "    # print(post_vec)\n",
    "    # 거리 계산\n",
    "    d = dist_norm(post_vec, new_post_vec)\n",
    "    # 기준값보다 작을 때 처리\n",
    "    if d < best_distance :\n",
    "        # 거리값\n",
    "        best_distance = d\n",
    "        # 유사한 인덱스\n",
    "        best_index = i\n",
    "        # 유사한 문장\n",
    "        best_doc = contents[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6288361746517446"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'길동이는 공원에서 산책하고 노는 것을 싫어해요'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
