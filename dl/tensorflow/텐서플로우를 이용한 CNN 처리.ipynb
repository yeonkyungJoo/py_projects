{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "- 합성곱 신경망( CNN : Convolutional Neural Network )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1998 : 얀 레쿤 교수 제안\n",
    "- 이미지 인식 분야에 강력한 성능 발휘\n",
    "- 음성인식, 자연어 처리에도 사용 → 활용성이 높아지고 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 인식 대회 ILSVRC (ImageNet Large Scale Recognition Competition)\n",
    "    - 2010 : NEC-UIUC\n",
    "    - 2011 : XRCE\n",
    "    - 2012 : AlexNet(CNN 알고리즘 기반, 딥러닝 시도)\n",
    "    - 2013 : ZFNet\n",
    "    - 2014 : GoogLeNet(Inception v2), VGGNet 더 유명(간결함, 편의성)\n",
    "    - 2015 : ResNet → 사람의 정확도(오차율 5%)를 돌파\n",
    "    - 2016 : GoogLeNet-v4\n",
    "    - 2017 : SENet → 2.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './data/7.ILSVRC_랭킹.png' width = '400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './data/5.CNN_도식.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 구성\n",
    "    - [ 입력층 ] →\n",
    "    - [ 중간층 : [합성곱층][풀링층]...[합성곱층][풀링층][전결합층] ] →\n",
    "    - [ 출력층 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중간층\n",
    "    - 합성곱 은닉 계층\n",
    "        - 합성곱층(Convolution Layer)\n",
    "        - 풀링층(Pooling Layer)\n",
    "    - 전결합층(완전 연결 은닉 계층)\n",
    "<img src = './data/3.CNN_중간층.jpeg'>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱층\n",
    "    - 이미지의 특징을 추출\n",
    "    - 입력 x의 이미지 일부분을 조금씩 잘라가면서, 가중치 필터(W)를 적용(평활화, 윤곽선 검출)\n",
    "        - 평활화 : 명암의 분포를 균일하게 처리\n",
    "        - 윤곽선 검출 : 이미지 내부 대상들의 윤곽만 추출\n",
    "    - 움직이는 크기 한 픽셀에서 n칸으로 이동 → 스트라이드(stride)\n",
    "    - 가중치 필터 W = kernel(커널), 편향 b(바이어스, bias) 필요\n",
    "    - 입력층 28x28이라면 784개에 대한 가중치 필요 → 연산량도 많고, 시간도 많이 걸리므로 비효율적 → **컨볼루션 계층 도입** → 3x3으로 줄이면, 가중치는 9개만 있으면 되므로 계산량과 학습량이 줄어들어 효율적\n",
    "    - 커널이 1개면 비효율적 → **하이퍼 파라미터 조정을 통해서 커널의 수, 크기 등을 조절하여 계층 처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './data/dp1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 풀링층\n",
    "    - 합성곱층으로 얻는 특징 맵 C를 축소하는 층\n",
    "    - 특징을 유지한 상태로 축소\n",
    "    - 직선 인식 → 직선이 미세하게 흐트러지더라도 직선으로 인지한다\n",
    "    - 축소방법 : 최대 풀링, 최소 풀링, 평균 풀링\n",
    "    <img src = './data/dp2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전결합층\n",
    "    - 각 층의 유닛 통합\n",
    "    - 2차원 특징 맵들을 1차원으로 전개\n",
    "    - 활성화 함수(relu, sigmoid)가 사용되고, 특성을 더욱 강조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집\n",
    "mnist = tf.keras.datasets.mnist.load_data( path='mnist.npz' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mnist), len(mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용\n",
    "len(mnist[0][0]), len(mnist[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용\n",
    "len(mnist[1][0]), len(mnist[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 확인\n",
    "mnist[0][1][:2]  # 벡터화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우의 샘플에서 획득\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('./data/mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용\n",
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 조건을 만족하는 인덱스\n",
    "print(np.where(mnist.train.labels[0])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 784의 제곱근\n",
    "pixel_size = int(np.sqrt( mnist.train.images.shape[1] ))\n",
    "pixel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 1개에 대한 레이블 크기\n",
    "pixels = mnist.train.images.shape[1]\n",
    "nums = mnist.train.labels.shape[1]\n",
    "pixels, nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우의 CNN 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 채널 → 손글씨 이미지 데이터 → n개(None)\n",
    "# 이미지 1개당 특성(픽셀) pixels개\n",
    "x = tf.placeholder( tf.float32, shape = [None, pixels], name = 'x' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 → 손글씨가 0 - 9로 레이블값 : 데이터 n개(None), 출력의 종류, 분류개수(nums)\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, nums], name = 'y_')\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (가중치, 필터, 커널)을 초기화하는 함수 구현\n",
    "# name을 붙인 이유는 합성곱층마다 사용이 될 것이므로, 이를 구분하기 위함\n",
    "# → 텐서보드에서 그래프를 구분하기 위함\n",
    "def weight_variable( name, shape ) :\n",
    "    \n",
    "    # 절단 정규 분포 함수\n",
    "    # 평균값을 기준으로 표준편차보다 크거나 작은 데이터는 제외하는 난수 생성\n",
    "    # stddev : 표준편차\n",
    "    W_init = tf.truncated_normal(shape, stddev=0.1)\n",
    "    # 가중치 변수 생성\n",
    "    W = tf.Variable( W_init, name = 'W_' + name )\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바이어스(편향)\n",
    "# 필터를 통과한 값을 전체적으로 올리거나, 내리거나\n",
    "def bias_variable(name, size) :\n",
    "    # 0.1 임시값 - 파라미터에 따라 다르게 나온다\n",
    "    b_init = tf.constant( 0.1, shape = [size] )\n",
    "    b = tf.Variable( b_init, name = 'b_'+ name )\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 계층 생성\n",
    "def conv2d(x, W) :\n",
    "    # 스트라이드 : 커널(필터, 가중치) 얼마 단위로 이동시킬 것인가\n",
    "    return tf.nn.conv2d( x, W, strides = [1, 1, 1, 1], padding = 'SAME' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱층 1 생성\n",
    "# 텐서보드 상에서 그래프에 관련된 범위(scope)를 부여하여 관계를 쉽게 확인\n",
    "c_name1 = 'conv1'\n",
    "with tf.name_scope(c_name1) as scope :\n",
    "    # 5, 32는 설정값\n",
    "    # 가중치 or 필터 or 커널 생성\n",
    "    # W_conv1 = weight_variable( c_name1, [ filter_height, filter_width, in_channels, out_channels ] )\n",
    "    W_conv1 = weight_variable( c_name1, [5, 5, 1, 32] )\n",
    "    # 편향/바이어스 생성\n",
    "    b_conv1 = bias_variable( c_name1, 32 )\n",
    "    # 입력 데이터에 대한 행렬 준비\n",
    "    # x_img = tf.reshape( x, [batch, in_height, in_width, in_channels] )\n",
    "    x_img = tf.reshape(x, [-1, pixel_size, pixel_size, 1])\n",
    "    # 컨볼루젼 생성\n",
    "    # 활성화 함수를 사용 마감처리\n",
    "    h_conv1 = tf.nn.relu( conv2d( x_img, W_conv1 ) + b_conv1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링층 생성 → 크기를 대폭 줄여서, 데이터량을 줄이고 특징은 유지\n",
    "# 최대 풀링, 최소 풀링 등 존재\n",
    "# x의 shape : (?, 28, 28, 32)\n",
    "def max_pool(x) :\n",
    "    # 2, 2는 설정값\n",
    "    return tf.nn.max_pool( x, ksize = [1, 2, 2, 1],\n",
    "                          strides = [1, 2, 2, 1], padding = 'SAME' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.max_pool(\n",
    "    value,\n",
    "    ksize,\n",
    "    strides,\n",
    "    padding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('pool1') as scope :\n",
    "    h_pool1 = max_pool( h_conv1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?, 14, 14, 32) \n",
    "# 이전층 대비 가로, 세로 길이가 반으로 줄었다\n",
    "h_pool1.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱층2 생성 → 출력 : 채널이 64로 늘어난다\n",
    "\n",
    "c_name2 = 'conv2'\n",
    "with tf.name_scope(c_name2) as scope :\n",
    "    W_conv2 = weight_variable( c_name2, [5, 5, 32, 64] )\n",
    "    b_conv2 = bias_variable( c_name2, 64 )\n",
    "    h_conv2 = tf.nn.relu( conv2d( h_pool1, W_conv2 ) + b_conv2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링층2 생성 → 가로, 세로길이가 7로, 즉 반으로 줄어든다\n",
    "with tf.name_scope('pool2') as scope :\n",
    "    h_pool2 = max_pool( h_conv2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?, 7, 7, 64)\n",
    "h_pool2.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전결합층\n",
    "# 현재 이미지의 크기는 합성곱층을 2번 통과했으므로 \n",
    "# → 28/2/2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_name = 'fc'\n",
    "with tf.name_scope('fully_connected_layer') as scope :\n",
    "    \n",
    "    n = 7 * 7 * 64\n",
    "    # 가중치\n",
    "    # 출력 채널을 1024개로 설정\n",
    "    W_fc = weight_variable( fc_name, [n, 1024] )\n",
    "    # 편향\n",
    "    b_fc = bias_variable( fc_name, 1024 )\n",
    "    # [-1, n] * [n, 1024] + [1024] = [-1, 1024]\n",
    "    h_pool2_fc = tf.reshape( h_pool2, [-1, n] )\n",
    "    # 활성화 함수 통과\n",
    "    h_fc = tf.nn.relu(tf.matmul( h_pool2_fc , W_fc ) + b_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?, 1024)\n",
    "h_fc.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과잉 적합 막기(옵션)\n",
    "with tf.name_scope('dropout') as scope :\n",
    "    keep_prob = tf.placeholder( tf.float32 )\n",
    "    h_fc_drop = tf.nn.dropout( h_fc, rate = 1-keep_prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?, 1024)\n",
    "h_fc_drop.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 구성 - 활성화 함수로 softmax 사용\n",
    "ro_name = 'read_out'\n",
    "with tf.name_scope(ro_name) as scope :\n",
    "    W_ro = weight_variable( ro_name, [1024, 10]) \n",
    "    b_ro = bias_variable( ro_name, 10 )\n",
    "    y_conv = tf.nn.softmax( tf.matmul( h_fc_drop, W_ro ) + b_ro )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?, 10)\n",
    "y_conv.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "# 손실값 정의\n",
    "with tf.name_scope('loss') as scope :\n",
    "    # 크로스 엔트로피\n",
    "    # 비용(cost)/손실(loss) : 원하는 결과에 얼마나 떨어져 있는가, 이 격차를 줄인다\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "with tf.name_scope('training') as scope :\n",
    "    # 확률적 경사 하강법\n",
    "    # 무작위로 초기화한 매개변수를 손실함수가 작아지도록 지속적으로 반복하여 변경\n",
    "    optimizer = tf.train.AdamOptimizer( 1e-4 )\n",
    "    train_step = optimizer.minimize( cross_entropy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "with tf.name_scope('predict') as scope :\n",
    "    predict_step = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy_step = tf.reduce_mean(tf.cast(predict_step, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 및 예측 평가 시 사용할 수 있는 구조로 변형\n",
    "def set_feed( images, labels, prob ) :\n",
    "    return { x : images, y_: labels, keep_prob : prob }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 시작 → 연산 시작\n",
    "with tf.Session() as sess :\n",
    "    # 텐서플로우 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 테스트 전용 피드 데이터\n",
    "    test_fd = set_feed( mnist.test.images, mnist.test.labels, 1 )\n",
    "    \n",
    "    # 학습\n",
    "    for step in range( 3000 ) : # 10000 ) :\n",
    "        # 데이터를 50개씩 사용하겠다\n",
    "        # 훈련용 데이터에서 50개 획득\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        # 0.5는 설정값\n",
    "        fd = set_feed( batch[0], batch[1], 0.5 )\n",
    "        # 훈련\n",
    "        _, loss = sess.run( [ train_step , cross_entropy ], feed_dict = fd  )\n",
    "        # 100번째마다 출력\n",
    "        if step % 100 == 0 :\n",
    "            acc = sess.run( accuracy_step, feed_dict = test_fd )\n",
    "            print('step = %s loss = %s acc = %s' %(step, loss, acc))\n",
    "    # 최종 결과 출력\n",
    "    acc = sess.run( accuracy_step, feed_dict = test_fd )\n",
    "    # print('step = %s loss = %s acc = %s' %(step, loss, acc))\n",
    "    print('정확도 =', acc)\n",
    "    \n",
    "    # 텐서보드 기록\n",
    "    tf.summary.FileWriter('./log_tf_cnn', graph = sess.graph)\n",
    "    \n",
    "    # 종료 후\n",
    "    # $ tensorboard --logdir=log_tf_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
