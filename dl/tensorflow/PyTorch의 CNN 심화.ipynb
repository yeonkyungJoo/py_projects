{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torchvision에서 가져오는 데이터는 10개의 사물 분류 이미지\n",
    "    - Cifar-10 데이터\n",
    "        - 6만장\n",
    "        - RGB\n",
    "        - 높이, 너비는 각각 32\n",
    "        - 비행기, 자동차, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [18:50, 231186.46it/s]                                                                                     "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "train_dataset = datasets.CIFAR10('./dataset', train=True, download=True, \n",
    "                transform = transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./dataset', train=False,\n",
    "                transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, torchvision.datasets.cifar.CIFAR10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( train_dataset ), len( test_dataset ), type( train_dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print( train_dataset.classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47904"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 이미지\n",
    "idx = torch.randint( 0, len(train_dataset), (1,) ).item()\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image = train_dataset[idx][0]\n",
    "random_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 분류값\n",
    "train_dataset[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bird'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes[ train_dataset[idx][1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터의 차원 이동을 하여 그릴 수 있게 조정\n",
    "plt.imshow( random_image.numpy().transpose(1, 2, 0) )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 'cpu', 30, 180)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수, 학습용 상수\n",
    "BATCH = 128\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "STEP = 30\n",
    "PRINT_STEP = 180\n",
    "\n",
    "BATCH, DEVICE, STEP, PRINT_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2216f68b160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader( train_dataset, batch_size= BATCH, shuffle= True )\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2216f6b7160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader( test_dataset, batch_size= BATCH, shuffle= True )\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 79)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN 클래스 생성\n",
    "    - 합성곱 형태 정의\n",
    "        - case1) 합성곱층 : nn.Conv2d + nn.ReLU, 풀링층 : nn.MaxPool2d\n",
    "        - case2) 합성곱층 : nn.Conv2d + nn.ReLU, nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src = './data/8.cnn_value.jpeg'></td>\n",
    "    <td><img src = './data/6.cnn_shape.jpeg'></td>\n",
    "</tr>\n",
    "\n",
    "- W(or H) = (W(in) + 2*P - K)/S + 1를 이용하여 레이어를 통과할 때 크기를 계산\n",
    "- features의 수는 채널 수 * 이미지 세로 * 이미지 가로\n",
    "\n",
    "- nn.Module\n",
    "    - 신경망 모듈의 기본 클래스\n",
    "    - 모든 모델은 이 클래스를 상속받아야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self) :\n",
    "        # 부모 생성자 호출\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # 합성곱층 생성\n",
    "        self.conv1 = nn.Conv2d( \n",
    "                        in_channels = 3,\n",
    "                        out_channels = 8,\n",
    "                        kernel_size = 5,\n",
    "                        stride = 1,\n",
    "                        padding = 1\n",
    "                    )\n",
    "        self.conv2 = nn.Conv2d( \n",
    "                        in_channels = 8,\n",
    "                        out_channels = 16,\n",
    "                        kernel_size = 2,\n",
    "                        stride = 1,\n",
    "                        padding = 0\n",
    "                    ) \n",
    "        \n",
    "        # 렐루 생성\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        # 풀링 생성\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "        \n",
    "        # 전결합층 생성\n",
    "        # (128, 16, 7, 7) → (128, 16*7*7) = (128, 784)\n",
    "        # (batch, 16, 7, 7) → (batch, 16*7*7) = (batch, 784)\n",
    "        # reshape = view\n",
    "        # x.view( batch 크기, \"나머지는 2차원에 맞게 알아서 펴라\" )\n",
    "        self.flatten = lambda x : x.view( x.size(0) , -1 )\n",
    "        self.fc = nn.Linear( 784, 10 )\n",
    "        \n",
    "    '''\n",
    "    - 모든 호출에서 사용하는 연산 정의\n",
    "    - 모든 서브클래스(CNN)은 이 함수를 반드시 재정의해야 한다\n",
    "    - 층을 정의한다(레이어 정의)\n",
    "    - x : 입력 텐서, 입력 데이터\n",
    "    '''\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        # 합성곱층의 체이닝\n",
    "        # 컨볼루젼1\n",
    "        x = self.conv1(x)\n",
    "        # 렐루\n",
    "        x = self.relu(x)\n",
    "        # 풀링\n",
    "        x = self.pool(x)\n",
    "        # 컨볼루젼2\n",
    "        x = self.conv2(x)\n",
    "        # 렐루\n",
    "        x = self.relu(x)\n",
    "        # 풀링\n",
    "        x = self.pool(x)\n",
    "        # 전결합층\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        # 출력계층은 작업 후 처리로 설정\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "model = CNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수, 크로스엔트로피\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저, 확률적 경사 하강법\n",
    "optimizer = optim.Adam( model.parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils_mod import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3098\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.7915\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.6922\n",
      "Test set: Average loss: 1.6197, Accuracy: 4248/10000 (42.48%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.5471\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.4780\n",
      "Train Step: 2 (92.16%)  \tLoss: 1.5369\n",
      "Test set: Average loss: 1.5089, Accuracy: 4629/10000 (46.29%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 1.6616\n",
      "Train Step: 3 (46.08%)  \tLoss: 1.4915\n",
      "Train Step: 3 (92.16%)  \tLoss: 1.3227\n",
      "Test set: Average loss: 1.4510, Accuracy: 4776/10000 (47.76%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 1.6230\n",
      "Train Step: 4 (46.08%)  \tLoss: 1.3998\n",
      "Train Step: 4 (92.16%)  \tLoss: 1.3969\n",
      "Test set: Average loss: 1.3517, Accuracy: 5236/10000 (52.36%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 1.3973\n",
      "Train Step: 5 (46.08%)  \tLoss: 1.3041\n",
      "Train Step: 5 (92.16%)  \tLoss: 1.3450\n",
      "Test set: Average loss: 1.3098, Accuracy: 5406/10000 (54.06%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 1.3290\n",
      "Train Step: 6 (46.08%)  \tLoss: 1.1292\n",
      "Train Step: 6 (92.16%)  \tLoss: 1.1899\n",
      "Test set: Average loss: 1.2809, Accuracy: 5456/10000 (54.56%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 1.2576\n",
      "Train Step: 7 (46.08%)  \tLoss: 1.2735\n",
      "Train Step: 7 (92.16%)  \tLoss: 1.1516\n",
      "Test set: Average loss: 1.2548, Accuracy: 5504/10000 (55.04%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 1.2714\n",
      "Train Step: 8 (46.08%)  \tLoss: 1.2552\n",
      "Train Step: 8 (92.16%)  \tLoss: 1.3116\n",
      "Test set: Average loss: 1.2300, Accuracy: 5657/10000 (56.57%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 1.2284\n",
      "Train Step: 9 (46.08%)  \tLoss: 1.2754\n",
      "Train Step: 9 (92.16%)  \tLoss: 1.4555\n",
      "Test set: Average loss: 1.2358, Accuracy: 5583/10000 (55.83%)\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 1.1982\n",
      "Train Step: 10 (46.08%)  \tLoss: 1.2296\n",
      "Train Step: 10 (92.16%)  \tLoss: 1.1673\n",
      "Test set: Average loss: 1.2459, Accuracy: 5649/10000 (56.49%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 1.2217\n",
      "Train Step: 11 (46.08%)  \tLoss: 1.1459\n",
      "Train Step: 11 (92.16%)  \tLoss: 1.3159\n",
      "Test set: Average loss: 1.2296, Accuracy: 5691/10000 (56.91%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 0.9702\n",
      "Train Step: 12 (46.08%)  \tLoss: 1.2165\n",
      "Train Step: 12 (92.16%)  \tLoss: 1.0795\n",
      "Test set: Average loss: 1.2201, Accuracy: 5758/10000 (57.58%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 1.1490\n",
      "Train Step: 13 (46.08%)  \tLoss: 1.1976\n",
      "Train Step: 13 (92.16%)  \tLoss: 1.0582\n",
      "Test set: Average loss: 1.1758, Accuracy: 5894/10000 (58.94%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 1.0488\n",
      "Train Step: 14 (46.08%)  \tLoss: 1.1673\n",
      "Train Step: 14 (92.16%)  \tLoss: 1.2162\n",
      "Test set: Average loss: 1.1970, Accuracy: 5852/10000 (58.52%)\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 1.1192\n",
      "Train Step: 15 (46.08%)  \tLoss: 1.0373\n",
      "Train Step: 15 (92.16%)  \tLoss: 1.1711\n",
      "Test set: Average loss: 1.1811, Accuracy: 5846/10000 (58.46%)\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 1.1005\n",
      "Train Step: 16 (46.08%)  \tLoss: 1.0136\n",
      "Train Step: 16 (92.16%)  \tLoss: 1.1292\n",
      "Test set: Average loss: 1.1549, Accuracy: 5975/10000 (59.75%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 0.9733\n",
      "Train Step: 17 (46.08%)  \tLoss: 1.1799\n",
      "Train Step: 17 (92.16%)  \tLoss: 1.2946\n",
      "Test set: Average loss: 1.1607, Accuracy: 5977/10000 (59.77%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 1.1290\n",
      "Train Step: 18 (46.08%)  \tLoss: 1.2250\n",
      "Train Step: 18 (92.16%)  \tLoss: 1.0409\n",
      "Test set: Average loss: 1.1463, Accuracy: 6012/10000 (60.12%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 1.0433\n",
      "Train Step: 19 (46.08%)  \tLoss: 1.1961\n",
      "Train Step: 19 (92.16%)  \tLoss: 1.2184\n",
      "Test set: Average loss: 1.1467, Accuracy: 5962/10000 (59.62%)\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 1.1196\n",
      "Train Step: 20 (46.08%)  \tLoss: 1.1146\n",
      "Train Step: 20 (92.16%)  \tLoss: 0.9071\n",
      "Test set: Average loss: 1.1371, Accuracy: 6010/10000 (60.10%)\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 1.0035\n",
      "Train Step: 21 (46.08%)  \tLoss: 1.0830\n",
      "Train Step: 21 (92.16%)  \tLoss: 1.1566\n",
      "Test set: Average loss: 1.1528, Accuracy: 6001/10000 (60.01%)\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.9743\n",
      "Train Step: 22 (46.08%)  \tLoss: 1.1715\n",
      "Train Step: 22 (92.16%)  \tLoss: 1.1249\n",
      "Test set: Average loss: 1.1429, Accuracy: 6038/10000 (60.38%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 0.9966\n",
      "Train Step: 23 (46.08%)  \tLoss: 1.0245\n",
      "Train Step: 23 (92.16%)  \tLoss: 0.9470\n",
      "Test set: Average loss: 1.1261, Accuracy: 6087/10000 (60.87%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 1.1092\n",
      "Train Step: 24 (46.08%)  \tLoss: 0.9440\n",
      "Train Step: 24 (92.16%)  \tLoss: 0.9817\n",
      "Test set: Average loss: 1.1232, Accuracy: 6098/10000 (60.98%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 1.0239\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.9862\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.8778\n",
      "Test set: Average loss: 1.1325, Accuracy: 6044/10000 (60.44%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 1.0090\n",
      "Train Step: 26 (46.08%)  \tLoss: 0.9741\n",
      "Train Step: 26 (92.16%)  \tLoss: 1.0220\n",
      "Test set: Average loss: 1.1256, Accuracy: 6049/10000 (60.49%)\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 1.0851\n",
      "Train Step: 27 (46.08%)  \tLoss: 1.0420\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.9526\n",
      "Test set: Average loss: 1.1271, Accuracy: 6046/10000 (60.46%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 0.9280\n",
      "Train Step: 28 (46.08%)  \tLoss: 0.9079\n",
      "Train Step: 28 (92.16%)  \tLoss: 0.8062\n",
      "Test set: Average loss: 1.1073, Accuracy: 6145/10000 (61.45%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 0.9799\n",
      "Train Step: 29 (46.08%)  \tLoss: 0.9786\n",
      "Train Step: 29 (92.16%)  \tLoss: 0.9800\n",
      "Test set: Average loss: 1.1039, Accuracy: 6166/10000 (61.66%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 0.9832\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.9655\n",
      "Train Step: 30 (92.16%)  \tLoss: 0.9319\n",
      "Test set: Average loss: 1.1074, Accuracy: 6175/10000 (61.75%)\n",
      "discard previous state, best model state saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련 및 테스트\n",
    "main(\n",
    "    model        = model,                  # nn.model을 상속받은 클래스\n",
    "    train_loader = train_loader,           # 훈련 데이터\n",
    "    test_loader  = test_loader,            # 테스트 데이터\n",
    "    loss_func    = loss_func,              # 손실함수\n",
    "    optimizer    = optimizer,              # 최적화도구\n",
    "    n_step       = STEP,                   # 반복 스텝, 학습의 양\n",
    "    device       = DEVICE,                 # cpu, cuda\n",
    "    save_path    = 'cifar10_model_v1.pt',  # 학습 완료한 모델의 덤프\n",
    "    print_step   = PRINT_STEP     # 수행 시 얼마 간격으로 진행 상황을 출력할 것인가\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도가 낮다\n",
    "    - 더 큰 모델(이미지)을 이용하여 학습\n",
    "    - 데이터를 더 늘려서 학습\n",
    "    - 배치 정규화를 통해서 학습 성능을 향상 (채널 수, 스트라이드, 패딩, 커널사이즈 등)\n",
    "    - 알고리즘을 추가하여 개선하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ch_in': 3,\n",
       " 'n_in': 32,\n",
       " 'conv1': (32, 7, 1, 1),\n",
       " 'pool1': 2,\n",
       " 'conv2': (64, 5, 1, 0),\n",
       " 'pool2': 2,\n",
       " 'conv3': (128, 3, 1, 0),\n",
       " 'pool3': 2,\n",
       " 'fc': (250, 50, 10)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = [ ('ch_in', 3),\n",
    "           ('n_in', 32),  # 이미지의 사이즈(height or weight, 동일)\n",
    "           ('conv1', (32, 7, 1, 1)), ('pool1', 2),\n",
    "           ('conv2', (64, 5, 1, 0)), ('pool2', 2),\n",
    "           ('conv3', (128, 3, 1, 0)), ('pool3', 2),\n",
    "           ('fc', (250, 50, 10))\n",
    "         ]\n",
    "dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 (32, 7, 1, 1)\n",
      "pool1 2\n",
      "conv2 (64, 5, 1, 0)\n",
      "pool2 2\n",
      "conv3 (128, 3, 1, 0)\n",
      "pool3 2\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in config :\n",
    "    if 'conv' in k :\n",
    "        print(k, v)\n",
    "    elif 'pool' in k :\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 항목의 값\n",
    "dict(config)['ch_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컨볼루젼 계층의 총 개수\n",
    "# for k in dict(config) :\n",
    "#     if 'conv' in k :\n",
    "#         print(k)\n",
    "sum([ True for k in dict(config) if 'conv' in k ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1]\n",
    "a += [2, 3, 4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEx(nn.Module) :\n",
    "    \n",
    "    def __init__(self, config) :\n",
    "        super(CNNEx, self).__init__()\n",
    "        # 컨볼루젼 계층(conv, pool) 병행\n",
    "        self.convs = nn.Sequential(*self._make_layers(config) )\n",
    "        # 전결합층\n",
    "        # 전결합층 - flatten\n",
    "        self.flatten = lambda x : x.view( x.size(0), -1 )\n",
    "        # 전결합층 - 실제\n",
    "        self.fc = nn.Sequential(*self._make_layers(config, name = 'fc') )\n",
    "    \n",
    "    # 계층 연결\n",
    "    def forward(self, x) :\n",
    "        x = self.convs(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    # config의 구성에 맞춰서 name에 해당되는 계층을 자동 생성한다\n",
    "    def _make_layers(self, config, name = 'convs') :\n",
    "        \n",
    "        # [ 합, 배치정규, 렐루, 풀, 합, 배치정규, 렐루, 풀, 합, 배치정규, 렐루, 풀, ... ]\n",
    "        layers = []\n",
    "        ch_in = dict(config)['ch_in']\n",
    "        \n",
    "        if name == 'convs' :  # 합성곱층을 config에 설정된 값에 따라 완성한다\n",
    "            for (k, v) in config :\n",
    "                if 'conv' in k :  # 합성곱층\n",
    "                    # print(k, v)\n",
    "                    # (32, 7, 1, 1) : (출력 채널, 커널 크기, 스트라이드, 패딩)\n",
    "                    ch_out, k, s, p = v\n",
    "                    \n",
    "                    # 레이어 생성\n",
    "                    layers += [ \n",
    "                        nn.Conv2d(\n",
    "                                in_channels = ch_in,      # 입력채널\n",
    "                                out_channels = ch_out,    # 출력채널\n",
    "                                kernel_size = k,          # 커널 사이즈\n",
    "                                stride = s,               # 스프라이드 사이즈\n",
    "                                padding = p               # 패딩 사이즈\n",
    "                        ),\n",
    "                        # 학습능력을 향상시키기 위해 배치 정규화 추가\n",
    "                        nn.BatchNorm2d(ch_out),\n",
    "                        nn.ReLU(inplace = True)\n",
    "                        ]\n",
    "                    # 현재 완료된 layer의 출력 채널 수를\n",
    "                    # 다음 번 layer의 입력 채널 수로 설정\n",
    "                    ch_in = ch_out\n",
    "                \n",
    "                elif 'pool' in k :  # 풀링층\n",
    "                    # print(k, v)\n",
    "                    layers += [ \n",
    "                        # 통상 커널사이즈와 동일하게 스트라이드 값을 부여\n",
    "                        # 만약 다르게 하고 싶으면 ('pool1', (2, 4)) 값을 추가 → 수정\n",
    "                        nn.MaxPool2d(kernel_size=v, stride = v)\n",
    "                    ]\n",
    "        elif name = 'fc' :\n",
    "            pass\n",
    "        \n",
    "        else :\n",
    "            print('잘못 입력했습니다.')\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    # fc의 입력 채널 수 계산\n",
    "    def _get_fc_input(self, config) :\n",
    "        config = dict( config )\n",
    "        n_in = config[n_in]  # 이미지의 사이즈(세로 혹은 가로) # 32\n",
    "        # 컨볼루젼의 계층이 몇 번 존재하는가?\n",
    "        convs_cnt = sum([ True for k in dict(config) if 'conv' in k ]) # 3\n",
    "        # conv1, conv2, conv3 → 1 ~ 3\n",
    "        for i in range(1, convs_cnt+1) :\n",
    "            ch_out, k, s, p = config['conv%s' % i ]\n",
    "            pool_k = config['pool%s' % i ]\n",
    "            # 컨볼루전 통과 후 사이즈\n",
    "            conv_n = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
