1. 연구 목표
 - MovieLens(무비렌즈) : 영화 평점 데이터
 - 사용자의 별점 수를 예측
 - 개요
  > 2006년도 넷플릭스의 프라이즈 경진 대회가 가장 유명
  > 추천 정확도를 기존 대비 10% 향상으로 목표 → '모든 것이 추천이다' 슬로건을 가지고 진행
    https://medium.com/@NetflixTechblog
  > 무비렌즈 데이터는 미네소타에서 제공, 넷플릭스와 비슷한 정보를 기반으로 연구용으로 공개한 데이터
  
2. 시스템 정의
 
 - 추천 시스템
  > 목적 : 어떤 사용자 행동이나 아이템에 대한 정보로부터, 사용자가 선호할만한 관련 아이템을 제시하는 것?
  > 특징 : 검색만으로는 사용자가 원하는 콘텐츠를 찾기가 어려운 경우 (동영상/음악 스트리밍, 쇼핑몰 등) 추천을 통해서 자신이 선호하는 콘텐츠를 발견하도록 도움을 주는 시스템
    → 서비스 제공자들도 상품 구매 전환율을 높이거나, 활성 사용자 수를 늘리는 기회로 사용
  
  - 응용 분야
   
   1) 개요 추천
    > 금주의 인기 상품 → 통계 활용, 편집자 선택 아이템들을 추천
    > 개인화가 되어 있지 않는 추천 → 시스템을 처음 이용하는 사용자, 가끔 이용하는 사용자에게 적합
   
   2) 사용자 평가
    > 다른 사람의 추천 → 해당 아이템의 신뢰를 줄 수 있는 근거가 된다
       → 사용자는 스스로 납득을 하고 선택을 할 수 있게 하는 방향으로 전개
    > 다른 사용자의 별점, 댓글을 보여주거나, 평균 평점 노출
   
   3) 알림 서비스
    > 푸시 / 이메일 등을 통해 사용자가 흥미를 느낄 아이템을 추천 혹은 사이트 재방문 유도
   
   4) 연관 아이템 추천
    > 원래 아이템과 함께 연관된 아이템을, 혹은 그 정보를 제시하여 동시 구매를 유도
    > 다른 아이템과 비교하게 함
    > 전자상거래의 정석
   
   5) 개인화
    > 인기 아이템 목록 / 편집자 추천 목록 → 사용자가 흥미를 느끼는 아이템을 노출, 사용자 마음에 드는 아이템을 찾도록 도움을 주는 시스템
    > 검색 결과도 개인화를 적용
        
3. 데이터 설계/획득
  
 - 선호 데이터
  > 사용자가 특정 아이템을 얼마나 선호하는가?
 - 검색 쿼리
  > '7000원 이하 햄버거집' 검색
 - 비평, 후기
  > 상품 및 업체에 대한 댓글평
 - 아이템 특징
  > 상품 설명에 쓰인 단어 등에 대한 정보
 - 인구적 특징
  > 사용자의 연령, 성별
 - 맥락적 특징
  > 추천받은 아이템을 사용한 날짜, 위치 정보, 재고 현황 등 데이터를 통한 맥락적, 연관적 정보

4. 영화 추천 기준 평가 데이터 관련
 
 - 데이터가 매우 희소(많이 없다), 오래된 영화일수록 평가가 더 많다는 문제 내포
  → 추천 시스템 구축이 어렵다
 
 - 기준 평가
  > 사람마다 지금까지(현재 시점) 본 영화가 모두 다르다
  > 인기 영화는 평가 정보가 많다. 아닌 영화는 정보가 적다 → 추천이 안 된다
  > 영화는 한 해에 엄청나게 쏟아지는데, 한 사용자는 평생 볼 수 있는 영화 수가 많지 않다. (상대적)
  > 평가 정보가 특정 아이템에 몰리게 될 수 있고, 평점 행렬의 요소 대부분이 값을 가지지 않게 된다
    → 결측치가 많다
  > 평점 행렬 : 각 사용자가 각 영화(아이템)에 대해 평점을 기재한 데이터 : 2차 행렬
                영화1        영화2        영화3
   -----------------------------------------------             
      사용자1     5                         1
      사용자2     4                         2
      사용자3                  3            3
  > 선호 데이터 → 평가 정보 → 정답 데이터로 활용 가능
  > 아이템의 평가 비용(음악은 1곡을 듣고 평가를 수행할 수 있다 → 3~5분이므로 상대적으로 선호 데이터를 구하기 쉽다)
  > 주택 구입, 결혼식 예식장 선정 등 → 시간이 많이 소요 → 선호 데이터 수집이 쉽지 않다
    → 간접 지표를 통해서 선호 데이터를 보충(페이지 노출, 클릭, 머문 시간 등)

5. 선호 데이터 수집 방법 : 명시적 데이터 / 묵시적 데이터
 
 - 명시적 데이터
  > 사용자에게 직접, 선호도를 물어서 답변을 구하는 방식
 
 - 묵시적 데이터
  > 상품을 구매하거나, 상품 정보를 열람 → 이 아이템에 흥미를 가지고 있다 → 이러한 데이터를 모으는 방법
                                      명시적             묵시적
   -------------------------------------------------------------------
     데이터 양                          X                  O
     데이터의 정확성                    O                  X
     미평가와 부정적 평가 구분          O                  X
     사용자의 인지성                    O                  X     

6. 추천 시스템 알고리즘
 
 - 협업 필터링 : collaborative filtering
  
  > 메모리 기반 협업 필터링 : memory-based collaborative filtering

   1) 사용자 기반 협업 필터링 :  used-based collaborative filtering
    → 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
    - 피어슨 상관관계, 코사인 유도, 자카드 계수 등 등장
    
   2) 아이템 기반 협업 필터링 : item-based collaborative filtering
    → 방금 막 가입한 사용자에게 적용하기에 적합
   
  > 모델 기반 협업 필터링 : model-based collaborative filtering
    → 회귀/분류 등 예측 모델을 학습해서 처리
 
 - 내용 기반 필터링 : content-based collaborative filtering
    → 영화는 메타정보(제목, 감독, 장르, 배우, 평판 등 간접 지표를 통해 나타나는 정보에 주목)
 
7. 사용자 기반 협업 필터링
 [나와 비슷한 사용자는 어떻게 찾을까?
 → 여러 개의 요소 중에서 '평점'을 기준으로 하겠다
 → 평점 행렬을 구성
 → 유사도를 측정
 → 그 기반 기술로 피어슨 상관관계, 코사인 유도, 자카드 계수가 있다]
 - 당신과 비슷한 상품을 산 고객은 이런 상품도 샀다
 - 사용자와 아이템의 쌍에 대한 평점 행렬이 있는 경우, 행렬의 누락된 요소에 해당하는 평점을 예측
  1) 사용자 정보를 벡터로 표현
  2) (이를 기반으로) 사용자 간의 유사도를 평가
  3) 방법
   평점 행렬 → rating[사용자별 영화별 평가점수 인덱스][영화별 인덱스]
   i번째 사용자(user[i]) U의 평점벡터 u = [ rating[i][0], rating[i][3], rating[i][m] ]
   j번째 사용자(user[j]) U의 평점벡터 v = [ rating[j][0], rating[j][3], rating[j][m] ]
   → 유사도 값 : 대상이 비슷하면 값이 커지고, 다르면 작아지는 척도(기준 지표)
   
   [numpy 직접 구현, scipy 함수로 지원]
   a) 피어슨 상관관계 : 
   → 가장 일반적인 상관계수
   ---------------------------------------------------------------
   import numpy as np
   def pearson_coefficient(u, v) :
       u_diff = u - np.mean(u)
       v_diff = v - np.mean(v)
       return np.dot( u_diff, v_diff ) / ( np.sqrt( sum( u_diff**2 ) )  * np.sqrt( sum( v_diff**2 ) ) ) )
   ---------------------------------------------------------------
   from scipy.spatial.distance import correlation
   def pearson_coefficient(u, v) :
       return 1 - correlation(u, v)
   
   b) 코사인 유도
   → 텍스트 문장 간의 거리를 측정하는 척도용
    ---------------------------------------------------------------
    from scipy.spatial.distance import cosine
    def cosine_similarity( u, v ):
        return 1 - cosine( u, v)
    ---------------------------------------------------------------
    import numpy as np
    def cosine_similarity_law( u, v ):
        return np.dot( u, v ) / ( np.sqrt( sum( u ** 2 ) ) * np.sqrt( sum( v ** 2) ) )
   
   c) 자카드 계수
   → 집합과 집합 사이의 거리를 계산, 0 ~ 1로만 존재
    ---------------------------------------------------------------
    from scipy.spatial.distance import jaccard
    def jaccard_similarity( u, v ):
        return 1- jaccard(u, v)
    ---------------------------------------------------------------
    import numpy as np
    def jaccard_similarity( u, v ):
        return np.dot( u, v ) / ( sum(np.absolute(u)) + sum(np.absolute(v)) - np.dot(u,v)  )

8. 아이템 기반 협업 필터링
 - 방금 막 가입한 사용자에게 적용하기에 적합
 - 활동이 아주 저조한 유저에게도 적용하기에 적합
 - 단, 예상되는 문제점은 인기 아이템만 노출 집중되는 문제가 있어서, 이외의 아이템들을 노출하는 보강 작업이 필요하다
 - 사용자 기반 협업 필터링과 유사점이 있고, 코사인 유도를 개선된 방식으로 사용
   adjusted cosine similarity : 개선된 코사인 유도
 - 영화 M의 평점 벡터를 m
   영화 N의 평점 벡터를 n
   사용자 평균 평점 u_mean
   ------------------------------------
   [numpy에서 구현]
   # 개선된 코사인 유도
   import numpy as np
   def adjusted_cosine_similarity( m, n, u_mean ):
        ad_m = m - u_mean
        ad_n = n - u_mean
        return np.dot( ad_m, ad_n ) / ( np.sqrt( sum( ad_m ** 2 ) ) * np.sqrt( sum( ad_n ** 2) ) )

9. 모델 기반 협업 필터링
 
 - 회귀/분류 등 예측 모델을 학습해서 처리
  → 지도/비지도 학습방법을 이용하여 기존 데이터가 가지는 규칙성에 따라 예측 및 추천하는 방법
 
 - 방법적 예
  
  a) 군집화를 사용하는 모델
   - 선호도가 비슷한 사용자들을 그룹으로 묶고, 특정 사용자가 자신이 속한 그룹이 선호하는 아이템을 추천
  
  b) 평점에 대한 회귀 모델
   - 선형 회귀
   - 모델 학습 후 평점 예측
   - 이 평점을 기준으로 그 점수에 도달해 있는 작품들을 추천(방법론은 좀 더 확장)
  
  c) 토픽을 이용한 모델
   - 멜로, sf 선호 등 잠재적인 의미를 드러내는 기법
   - 묵시적 데이터로 획득 가능
   - 방법
    1) 확률적 잠재 의미 분석 : PLSA
    2) 잠재 디리클레 할당 : LDA
   
  d) 행렬 분해 (행렬 인수분해 → fastFM, libFM 기능을 지원)

10. 내용 기반 필터링
 - 영화는 메타정보(제목, 감독, 장르, 배우, 평판 등 간접 지표를 통해 나타나는 정보에 주목)
 - 이런 정보들의 과거 정보들을 이용하여 추천 항목 구성/선택
 - 이런 정보 속에 사용자의 취향을 표출하는 단어를 알 수 있다면(발견되면), 그 정보를 통해서 취향에 맞는 영화들을 제시할 수 있다

11. 비교 (협업 필터링 vs 내용 기반 필터링)
 - 협업 필터링
  > 장르, 텍스트 등에 포함된 단어에 유사점이 없어도, 다양한 추천 결과를 얻을 수 있는 가능성이 크다
  > 도메인에 대한 지식, 관리할 필요도 없다
  > 문제점 : 데이터가 충분히 쌓이기 전까지 → 신규 사용자에게 새로운 아이템 추천 불가
   => 콜드 스타트 문제
   => 사용자가 적으면 준비된 추천 알고리즘을 적용한 추천 자체가 불가능 → 사용자가 늘지 않고 → 데이터가 없고 → 추천이 불가능한 악순환
   => 초반 전략과 데이터가 확보된 이후의 전략을 달리 하거나 적절히 섞어서 구현   
  > 아이템 기반 협업 필터링 같은 방식을 이용하여 누적 행동 데이터 등 누적 데이터가 없는 상황에서도 적절한 추천을 수행할 수 있다
  
 - 내용 기반 필터링
  > 아이템의 내용을 기초로 누적 행동 데이터가 없어도 적절한 추천이 가능
  > 한국어 → 형태소 분석, 유지 보수 측면 등 도메인에 특화된 이슈들이 제법 존재한다

12. 평가 척도
 - 분류 방식의 평가
  > 정확도 : accuracy
   1) 5단계 평점에서 4점 이상 받으면 정답으로 간주 → label화
   2) 예측결과와 사용자의 평점을 비교
   3) 정밀도 : precision → 예측 결과 중 실제 정답의 비율
   4) 재현율 : recall → 전체 정답 중 실제 정답을 맞춘 비율
 - 회귀 방식의 평가
  > 회귀로 예측한 별점의 개수 등 이런 형태로 추천 사용
  > RMSE(root mean squared error) : 평균 제곱근 오차 
   → 예측값과 실제값의 차이를 제곱한 값
   → 오차가 클수록 평균제곱근값도 커진다 
   → 작을수록 정확해지는 특징
   - MAE 대비 이상값에 취약한 단점을 가지고 있다
   
  > MAE(mean absolute error) : 평균 절대 오차
   → 예측값과 실제값의 차이에 대한 절대값으로부터 평점을 계산
   → 예측값과 실제값의 오차가 클수록 평균 절대 오차도 커진다
  - 순위상관
   → 추천한 아이템의 순서를 평가하는 지표 → 랭킹학습
  - 커버리지
   → 다양성을 평가 지표에 포함시켜, 전체 아이템 중에서 평점을 예측할 수 있는 아이템의 비율로 평가를 수행
   

13. 분석 및 데이터 획득
 - 목표
  > 무비렌즈 데이터를 이용하여 추천 시스템을 구축한다 → 상황인지 추천
  > 상황인지 추천 : 사용자와 아이템 정보와의 정보를 활용하여 추천하는 방식
 - 데이터 획득
  > (데이터 다운로드) wget http://files.grouplens.org/papers/ml-100k.zip
  > (압축 해제) unzip ml-100k.zip
 
14. docker
 - 오픈소스 라이브러리 중에는 윈도우에서 설치가 안 되는 유형이 제법 존재한다
 - 보편적으로 리눅스에서는 모두 작동하므로, 도커를 이용하여 리눅스 이미지를 구축하고, 우분투 18.04(late) 기반에서 환경을 구축하고, fastFM(인수분해머신기능 지원)를 컴파일 후 설치(os에 적합하게 → *.o 생성) 후 설치
 - 이렇게 구축된 추천시스템 라이브러리가 적용된 우분투 이미지를 도커 허브에 올려서, 어떤 PC든 재구축 시 빠르게 구성 가능
 - 향후 딥러닝 머신 사용 시 도커를 이용하여 구축 → 각기 자유롭게 사용이 가능하고, 하둡 클러스터의 시스템 베이스로 사용 가능하다