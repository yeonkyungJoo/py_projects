{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 알고리즘 적용 후 결과\n",
    "\n",
    "- load_breast_cancer() / 분류용 유방암 진단 데이터 세트를 활용\n",
    "- 1~4단계 생략, 바로 5단계 진입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모듈 가져오기\n",
    "# 알고리즘 및 기타 성능 관련 모듈\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 로드 및 분류(훈련용, 테스트용)\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (569, 30)\n",
    "# 데이터틑 569개\n",
    "# 유방암을 진단하는 항목(= 특성, 변수, feature, 컬럼)이 30개\n",
    "cancer['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# malignant : 악성\n",
    "# benign : 양성\n",
    "# 값을 나누기 위한 변수 형태 → 분류 변수 → 종류가 2개\n",
    "# => 이진데이터(0 or 1)\n",
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답(양성/악성)을 어떻게 표현했는지 샘플링\n",
    "cancer['target'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유방암을 진단하는 30개 항목 이름\n",
    "cancer['feature_names'], len(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분류 작업\n",
    "# random_state : 데이터를 섞는(셔플) 난수의 시드값\n",
    "# test_size : 테스트 데이터의 비율\n",
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data, # 데이터 : 독립\n",
    "                                                   cancer.target, # 답 : 종속\n",
    "                                                   random_state = 0,\n",
    "                                                   test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30), (426,), (143,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 알고리즘 생성\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 훈련\n",
    "svm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6293706293706294\n"
     ]
    }
   ],
   "source": [
    "# 5. 예측 및 평가\n",
    "print( svm.score( X_test, y_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svm.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293706293706294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "ac_score = metrics.accuracy_score( y_test, predict )\n",
    "ac_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리기를 적용해서 학습 후 결과\n",
    "\n",
    "- 데이터 자체를 훈련하기 전에 스케일링 작업을 수행하여 학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.185e+01, 1.746e+01, 7.554e+01, 4.327e+02, 8.372e-02, 5.642e-02,\n",
       "        2.688e-02, 2.280e-02, 1.875e-01, 5.715e-02, 2.070e-01, 1.238e+00,\n",
       "        1.234e+00, 1.388e+01, 7.595e-03, 1.500e-02, 1.412e-02, 8.578e-03,\n",
       "        1.792e-02, 1.784e-03, 1.306e+01, 2.575e+01, 8.435e+01, 5.178e+02,\n",
       "        1.369e-01, 1.758e-01, 1.316e-01, 9.140e-02, 3.101e-01, 7.007e-02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 수행\n",
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 해야하는 데이터를 넣어서 스케일러 생성\n",
    "scaler = MinMaxScaler().fit( X_train )\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23044157, 0.32157676, 0.21940433, ..., 0.31484671, 0.30277942,\n",
       "        0.09858323],\n",
       "       [0.20062473, 0.42116183, 0.19452699, ..., 0.06965208, 0.34042973,\n",
       "        0.06677161],\n",
       "       [0.62232003, 0.76929461, 0.60403566, ..., 0.56079917, 0.19850187,\n",
       "        0.07431457],\n",
       "       ...,\n",
       "       [0.11619102, 0.35726141, 0.11077327, ..., 0.17402687, 0.17524147,\n",
       "        0.17263545],\n",
       "       [0.12963226, 0.35311203, 0.11706171, ..., 0.        , 0.06780997,\n",
       "        0.06919848],\n",
       "       [0.21434995, 0.59004149, 0.21235575, ..., 0.33251808, 0.10782574,\n",
       "        0.21172767]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train = scaler.transform( X_train )\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘 생성\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "svm.fit( scaled_X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(scaler.transform( X_test ), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 후 결과\n",
    "\n",
    "- 머신러닝의 모형이 완성되고 난 후, **매개변수 최적화**를 통해 예측 성능을 더 극대화\n",
    "- 도구\n",
    " > validation_curve : 단일 하이퍼파라미터 최적화 도구  \n",
    " > GridSearchCV : 그리드를 이용한 복수 하이퍼파라미터 최적화  \n",
    " > ParameterGrid : 복수 하이퍼파라미터 최적화  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**알고리즘별 매개변수 목록**\n",
    "<img src = '../doc/매개변수.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알고리즘에 대한 파라미터 구성\n",
    "# 여기서는 알고리즘을 SVM 계열 사용\n",
    "# 수치는 범위 내 임의로 입력\n",
    "# 단, 최저값은 추천 데드라인보다 더 내려서 입력(가정)\n",
    "param_grid = {\n",
    "    'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'gamma' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 적용\n",
    "# cv → 교차 검증 수 (폴드(fold), None, 3, 5, )\n",
    "# 5 fold → 데이터의 총 개수를 5세트로 구성한다\n",
    "grid = GridSearchCV( SVC(), param_grid = param_grid, cv = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "# 5 fold 중에 4 폴드는 훈련용, 1 폴드는 검증용으로 사용\n",
    "grid.fit( scaled_X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812206572769953"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n",
    "# SVC(C=1, gamma=1) 이렇게 알고리즘을 생성하는 것이 최상의 결과치를 가져온다\n",
    "# (현 데이터 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score( scaler.transform( X_test ), y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 구성한 방식은 전처리 후 교차검증을 수행해서 최적 파라미터를 찾아냈다\n",
    "- 한편 순서상 전처리가 먼저 되어, 교차 검증 시 훈련용 데이터의 일부가 검증에 들어가는 문제가 발생된다 → 교차 검증 후 전처리를 수행하는 시퀀스를 맞춰야 하는데, 이를 구성하기 가장 좋은 방식은 **파이프라인 구축**\n",
    "- 스케일링한 데이터를 가지고 교차 검증을 수행하면, 스케일러 데이터 안에 예측대상 폴드(데이터 세트)가 구성되어 있어서, 신규 데이터 예측 시 불확실하게 처리가 된다. 이를 방지하게 위해 전처리 전에 교차 검증이 이루어져야 한다 → pipeline 구축을 통해 학습 모델과 전처리 단계를 연결하는 구성을 만들어야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|현재|개선(파이프라인이용)|\n",
    "|:---|---:|\n",
    "| <img src='../doc/cro.png'> | <img src='../doc/cro2.png'> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 인터페이스 적용 후 결과\n",
    "\n",
    "- 전처리기 이외에 다른 알고리즘, 처리기와 연결\n",
    "- 특성 추출, 특성 선택, 스케일 변경, 분류(회귀 or 군집) 등 4개를 포괄하는 파이프라인을 구축할 수 있다\n",
    "- 모든 추정기들은 transform() 함수를 가지고 있어서 언제든지 다음 단계로 연결시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 분류 비율이 75:25\n",
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data,\n",
    "                                                   cancer.target,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 구축\n",
    "# case 1 : 표준방법 → 전처리기, 알고리즘 등, 처리기에 이름 부여\n",
    "pipe_std = Pipeline( [ ( 'scaler', MinMaxScaler() ), ( 'classifier', SVC() ) ] )\n",
    "# case 2 : 간소화 방법 → 이름은 알아서 설정된다\n",
    "pipe_simple = make_pipeline( MinMaxScaler(), SVC() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 확인\n",
    "for pipe in pipe_std.steps :\n",
    "    print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1)))\n",
      "('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipe_simple.steps :\n",
    "    print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 데이터에 적용한 실 파이프\n",
    "pipe = Pipeline([\n",
    "                    ( 'preprocessing', StandardScaler() ),\n",
    "                    ( 'classifier', SVC() )\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier' : [ SVC() ],\n",
    "        'preprocessing' : [ StandardScaler(), MinMaxScaler() ],\n",
    "        # 매개변수가 동일명을 사용할 경우 구분\n",
    "        # (알고리즘 별칭)__(매개변수명)\n",
    "        'classifier__gamma' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__C' : [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    {\n",
    "        'classifier' : [ RandomForestClassifier(n_estimators = 100) ],\n",
    "        # 전처리기가 필요 없다\n",
    "        'preprocessing' : [ None ],\n",
    "        'classifier__max_features' : [1, 2, 3]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV( pipe, param_grid, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'classifier': [SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)], 'preprocessing': [StandardScaler(copy=True, with...=0,\n",
       "            warm_start=False)], 'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "grid.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__gamma': 0.01,\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['classifier', 'classifier__C', 'classifier__gamma', 'preprocessing'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577465"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score( X_test, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
